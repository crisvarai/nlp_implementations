{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWmVX4kNbis44QTEhJ+9wE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification\n",
        "\n",
        "In the same way that we can train neural networks for image classification, it is possible to train machine learning models capable of assigning a specific label to a piece of text."
      ],
      "metadata": {
        "id": "0KnlDB7gA8VT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "agPZpYyJBTy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchtext==0.10.0"
      ],
      "metadata": {
        "id": "nyJNtN1Npryj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext.legacy\n",
        "\n",
        "torchtext.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OqfSUMq-Bokm",
        "outputId": "069c2dd8-fc66-4401-b38e-64bfa4d0e290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.10.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torchtext contains a multitude of datasets that we can use, which are ideal when learning to work with neural networks for NLP tasks.\n",
        "\n",
        "The \"torchtext.legacy.data.Field\" class contains all the necessary tokenization and text processing logic."
      ],
      "metadata": {
        "id": "lWU7yy_8BrsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = torchtext.legacy.data.Field(tokenize = 'spacy')\n",
        "LABEL = torchtext.legacy.data.LabelField(dtype = torch.long)\n",
        "\n",
        "train_data, test_data = torchtext.legacy.datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyB1OkPJB7lg",
        "outputId": "628a2411-c4b6-4fe1-8ae7-66fbd670c885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:04<00:00, 17.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "3KmRrUgwCZ5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0831fb73-805e-47e9-c75e-2ee414ca6ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following way we can see a sample example of our dataset, which is composed of the text and the valuation."
      ],
      "metadata": {
        "id": "MZwH5jLTsG51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kNKrQNOtIuE",
        "outputId": "a500d841-ff28-47e5-b43d-15bebb7144c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['Like', 'his', 'earlier', 'film', ',', '\"', 'In', 'a', 'Glass', 'Cage', '\"', ',', 'Agustí', 'Villaronga', 'achieves', 'an', 'intense', 'and', 'highly', 'poetic', 'canvas', 'that', 'is', 'even', 'more', 'refined', 'visually', 'than', 'its', 'predecessor', '.', 'This', 'is', 'one', 'of', 'the', 'most', 'visually', 'accomplished', 'and', 'haunting', 'pictures', 'one', 'could', 'ever', 'see', '.', 'The', 'heightened', 'drama', ',', 'intensity', 'and', 'undertone', 'of', 'violence', 'threatens', 'on', 'the', 'the', 'melodramatic', 'or', 'farcical', ',', 'yet', 'never', 'steps', 'into', 'it', '.', 'In', 'that', 'way', ',', 'it', 'pulls', 'off', 'an', 'almost', 'impossible', 'feat', ':', 'to', 'be', 'so', 'over', '-', 'the', '-', 'top', 'and', 'yet', 'so', 'painfully', 'restrained', ',', 'to', 'be', 'so', 'charged', 'and', 'yet', 'so', 'understated', ',', 'and', 'even', 'the', 'explosives', 'finales', 'are', 'virtuosic', 'feasts', 'of', 'the', 'eye', '.', 'Unabashed', ',', 'gorgeous', ',', 'and', 'highly', 'tense', '...', 'this', 'film', 'is', 'simply', 'superb', '!'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n",
        "\n",
        "In this case we are going to build a vocabulary that will contain a certain number of words, for this the tokenizer will calculate the frequency of each word in the text and will keep the quantity that we specify."
      ],
      "metadata": {
        "id": "TiuiP3zZtOTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 10000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "len(TEXT.vocab), len(LABEL.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1R1yXE-uQdx",
        "outputId": "17fb0f43-b140-4005-89d6-33b94d59aa14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10002, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a vocabulary with the given length + two, these extra tokens correspond to the \"unk\" tokens, which will be assigned to unknown words and less frequent words that have not passed the first filter, and the \"pad\" token, which will be will use to make all phrases in a batch the same length."
      ],
      "metadata": {
        "id": "mGxAWKYtueTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIQVqbfB9h1o",
        "outputId": "f77ee18f-81f8-4672-fe2d-6b8434757898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 289838),\n",
              " (',', 275296),\n",
              " ('.', 236709),\n",
              " ('and', 156484),\n",
              " ('a', 156282),\n",
              " ('of', 144056),\n",
              " ('to', 133886),\n",
              " ('is', 109095),\n",
              " ('in', 87676),\n",
              " ('I', 77546)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.itos[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uA-N4Ze9jnv",
        "outputId": "4c1c9477-9c57-4db4-bca8-49daca647518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL.vocab.stoi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIvy5epg9vGp",
        "outputId": "ece9669c-0fa2-44cf-8aa9-f8f0102e2b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None, {'neg': 0, 'pos': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the DataLoader in charge of feeding the network with batches of phrases efficiently, using the torchtext.data.BucketIterator class, which will also join phrases of similar length minimizing the necessary padding."
      ],
      "metadata": {
        "id": "-f854O4w99Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "dataloader = {\n",
        "    'train': torchtext.legacy.data.BucketIterator(train_data, batch_size=64, shuffle=True, sort_within_batch=True, device=device),\n",
        "    'test': torchtext.legacy.data.BucketIterator(test_data, batch_size=64, device=device)\n",
        "}"
      ],
      "metadata": {
        "id": "rydDgsKG-Y3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "To classify the text we will use a many-to-one recursive network, which will receive the text word by word and we will use the last hidden state (which will contain information of the entire sentence) to generate our final prediction."
      ],
      "metadata": {
        "id": "Fysl33VG-fQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=2, num_layers=2, dropout=0.2, bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = torch.nn.GRU(\n",
        "            input_size=embedding_dim, \n",
        "            hidden_size=hidden_dim, \n",
        "            num_layers=num_layers, \n",
        "            dropout=dropout if num_layers > 1 else 0,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        self.fc = torch.nn.Linear(2*hidden_dim if bidirectional else hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        #text = [sent len, batch size]        \n",
        "        embedded = self.embedding(text)        \n",
        "        #embedded = [sent len, batch size, emb dim]        \n",
        "        output, hidden = self.rnn(embedded)        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        y = self.fc(output[-1,:,:].squeeze(0))  \n",
        "        \"\"\" Now the batch dimension is NOT the first, this is the default behavior of recursive \n",
        "            layers in Pytorch. You can modify this by adding the option batch_first=True in the \n",
        "            recursive layer (and make sure your dataloader uses the first dimension for the batch \n",
        "            as well. \"\"\"  \n",
        "        return y"
      ],
      "metadata": {
        "id": "bDqYNXHw-mPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We test that our network is well defined and the dimensions fit, we expect tensors with dimensions \"sequence length x batch\"."
      ],
      "metadata": {
        "id": "GMsoDgoxA-cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(dataloader['train']))\n",
        "\n",
        "batch.text.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdy1fRxECEsC",
        "outputId": "045ab5ea-a8ee-4e03-efbe-6433e2311c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([93, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the output, the model will give us two values, if the first value is greater than the second, we will assign class 0 (negative opinion) and vice versa."
      ],
      "metadata": {
        "id": "HRKXEpaMCGss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(input_dim=len(TEXT.vocab))\n",
        "outputs = model(torch.randint(0, len(TEXT.vocab), (100, 64)))\n",
        "outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjcWVfsdCdkD",
        "outputId": "da86a0bb-3db9-43ae-f7a9-e99076da1ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "qBp4iD7ZCfQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def fit(model, dataloader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch.text, batch.label\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch.text, batch.label\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
      ],
      "metadata": {
        "id": "FfISao9fCojJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(model, dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izj-pWN9Czry",
        "outputId": "51afe761-9f36-4551-e77e-6af1ec0681b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 0.59914 acc 0.66571: 100%|██████████| 391/391 [16:07<00:00,  2.48s/it]\n",
            "val_loss 0.52978 val_acc 0.73648: 100%|██████████| 391/391 [04:48<00:00,  1.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 loss 0.59914 val_loss 0.52978 acc 0.66571 val_acc 0.73648\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 0.34038 acc 0.85248: 100%|██████████| 391/391 [05:09<00:00,  1.27it/s]\n",
            "val_loss 0.32701 val_acc 0.85414: 100%|██████████| 391/391 [04:50<00:00,  1.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/5 loss 0.34038 val_loss 0.32701 acc 0.85248 val_acc 0.85414\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 0.23077 acc 0.90959: 100%|██████████| 391/391 [05:07<00:00,  1.27it/s]\n",
            "val_loss 0.26565 val_acc 0.88944: 100%|██████████| 391/391 [04:49<00:00,  1.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/5 loss 0.23077 val_loss 0.26565 acc 0.90959 val_acc 0.88944\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 0.16911 acc 0.93539: 100%|██████████| 391/391 [05:06<00:00,  1.27it/s]\n",
            "val_loss 0.27508 val_acc 0.88435: 100%|██████████| 391/391 [04:47<00:00,  1.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/5 loss 0.16911 val_loss 0.27508 acc 0.93539 val_acc 0.88435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.12250 acc 0.95609: 100%|██████████| 391/391 [05:06<00:00,  1.27it/s]\n",
            "val_loss 0.30675 val_acc 0.89325: 100%|██████████| 391/391 [04:49<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 loss 0.12250 val_loss 0.30675 acc 0.95609 val_acc 0.89325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Predictions\n",
        "\n",
        "In this case we only have two possible classes, but it is easy to intuit that if we were able to build a dataset with many more classes that more accurately describe the \"sentiment\" in a text, we could extract very valuable information."
      ],
      "metadata": {
        "id": "SeHQ4q8sC5r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def predict(model, X):\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(X).to(device)\n",
        "        pred = model(X)\n",
        "        return pred"
      ],
      "metadata": {
        "id": "8OU75KnnC7GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\", \"a waste of time\"]\n",
        "tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n",
        "indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n",
        "tensor = torch.tensor(indexed).permute(1,0)\n",
        "predictions = torch.argmax(predict(model, tensor), axis=1)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82aW_Y7hDFML",
        "outputId": "6d488c59-1a9f-448b-d8e9-a4f1339ce35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional Recurrent Networks\n",
        "\n",
        "Bidirectional recurrent networks allow, in general, to obtain better results when we work with sequential data.\n",
        "\n",
        "In applications such as text generation or time series prediction, we could not do this, however, for the text classification task, we can."
      ],
      "metadata": {
        "id": "NapBnFe3Dbtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(input_dim=len(TEXT.vocab), bidirectional=True)\n",
        "fit(model, dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We8BGPttDfPa",
        "outputId": "1570f7d9-aadc-417f-9938-ff9bf1f55f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.61430 acc 0.63929: 100%|██████████| 391/391 [33:54<00:00,  5.20s/it]\n",
            "val_loss 0.53135 val_acc 0.73211: 100%|██████████| 391/391 [10:43<00:00,  1.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 loss 0.61430 val_loss 0.53135 acc 0.63929 val_acc 0.73211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.32976 acc 0.85543: 100%|██████████| 391/391 [10:56<00:00,  1.68s/it]\n",
            "val_loss 0.30841 val_acc 0.86598: 100%|██████████| 391/391 [10:43<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 loss 0.32976 val_loss 0.30841 acc 0.85543 val_acc 0.86598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.22088 acc 0.91182: 100%|██████████| 391/391 [11:04<00:00,  1.70s/it]\n",
            "val_loss 0.36229 val_acc 0.84234: 100%|██████████| 391/391 [10:56<00:00,  1.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 loss 0.22088 val_loss 0.36229 acc 0.91182 val_acc 0.84234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.15653 acc 0.94101: 100%|██████████| 391/391 [10:57<00:00,  1.68s/it]\n",
            "val_loss 0.31984 val_acc 0.87363: 100%|██████████| 391/391 [10:42<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 loss 0.15653 val_loss 0.31984 acc 0.94101 val_acc 0.87363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.10502 acc 0.96264: 100%|██████████| 391/391 [11:05<00:00,  1.70s/it]\n",
            "val_loss 0.32625 val_acc 0.88268: 100%|██████████| 391/391 [10:53<00:00,  1.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 loss 0.10502 val_loss 0.32625 acc 0.96264 val_acc 0.88268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def predict(model, X):\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(X).to(device)\n",
        "        pred = model(X)\n",
        "        return pred"
      ],
      "metadata": {
        "id": "D5Np6PqqYv71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\", \"a waste of time\"]\n",
        "tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n",
        "indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n",
        "tensor = torch.tensor(indexed).permute(1,0)\n",
        "predictions = torch.argmax(predict(model, tensor), axis=1)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS9bKexPUSxL",
        "outputId": "0cf83086-0204-4eac-d0ff-1ca85a6a41c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}
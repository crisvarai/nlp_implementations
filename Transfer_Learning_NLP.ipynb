{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR541iBYuw0S"
      },
      "source": [
        "## Transfer Learning\n",
        "\n",
        "The idea is to train a neural network on a large dataset, with large computational resources, and once trained, use the knowledge that this model already has as a starting point for our particular case in the process known as \"fine tuning\".\n",
        "\n",
        "It allows to train neural networks faster, with lower computational requirements and allowing the training of networks with better performance with small datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxvkw20hvXMp"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI9WA1iCwHYC",
        "outputId": "253e3a1c-0aba-4ee6-95a5-1840fbb9e910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.10.0 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I32rmzcwNjr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext.legacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4g4pfyQwRWy",
        "outputId": "87e99679-e904-47c0-df15-961f6314375b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:10<00:00, 7.75MB/s]\n"
          ]
        }
      ],
      "source": [
        "TEXT = torchtext.legacy.data.Field(tokenize = 'spacy')\n",
        "LABEL = torchtext.legacy.data.LabelField(dtype = torch.long)\n",
        "\n",
        "train_data, test_data = torchtext.legacy.datasets.IMDB.splits(TEXT, LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPDv85GdwT9U",
        "outputId": "bbfa896e-1565-4c5c-dc9e-923fdc601a35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xifNoaIxy8D",
        "outputId": "32bcc4fd-9f7a-40c8-85ae-77ef4dd919e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['\"', 'Girlfight', '\"', 'is', 'much', 'more', 'of', 'a', 'coming', '-', 'of', '-', 'age', '-', 'story', 'than', 'it', 'is', 'a', 'fight', 'flick', '.', 'And', 'what', 'a', 'relief', 'to', 'have', 'one', 'in', 'an', 'urban', 'school', ',', 'with', 'naturalistic', ',', 'realistic', 'Latinos', 'and', 'believable', 'use', 'of', 'Brooklyn', 'project', 'settings', '.', '<', 'br', '/><br', '/>It', 'made', 'me', 'realize', 'that', 'virtually', 'all', 'Hollywood', 'high', 'school', 'movies', 'are', 'set', 'in', 'luxurious', 'suburbia', 'or', 'small', 'towns', '.', '(', 'Even', 'the', 'somewhat', 'comparable', '\"', 'Love', 'and', 'Basketball', '\"', 'which', 'focused', 'on', 'teen', 'African', '-', 'Americans', 'was', 'set', 'in', 'suburbia', '.', ')', 'While', 'these', 'kids', 'share', 'some', 'of', 'the', 'same', 'peer', 'problems', ',', 'those', 'issues', 'shrink', 'compared', 'to', 'the', 'other', 'struggles', 'of', 'these', 'kids', ',', 'where', 'high', 'school', 'graduation', 'could', 'be', 'the', 'major', 'accomplishment', 'of', 'their', 'lives.<br', '/><br', '/>The', 'feminist', 'element', 'here', 'is', 'riveting', 'in', 'its', 'originality', ',', 'as', 'you', 'hold', 'your', 'breath', 'to', 'see', 'if', 'she', 'can', 'have', 'a', 'relationship', '--', 'and', 'a', 'victory--', 'on', 'her', 'terms', '.', 'A', 'lots', 'of', 'audience', 'sympathy', 'goes', 'to', 'the', 'guy', 'who', 'is', 'challenged', 'to', 'rise', 'to', 'a', 'gender', '-', 'bending', '-', 'expectations', 'situation.<br', '/><br', '/>The', 'movie', 'does', 'drag', 'a', 'bit', 'here', 'and', 'there', ',', 'but', 'this', 'is', 'no', 'cheap', 'thrills', '\"', 'Rocky', '\"', 'fight', 'movie', ',', 'as', 'the', 'practices', 'and', 'fights', 'have', 'complex', 'outcomes', ',', 'and', 'all', 'the', 'relationships', '--', 'especially', 'with', 'fathers', 'and', 'father', '-', 'figures--', 'take', 'more', 'center', 'stage', 'than', 'the', 'center', 'ring', '.', '<', 'br', '/><br', '/>There', 'were', 'lots', 'of', 'interesting', 'music', 'credits', 'listed', 'at', 'the', 'end', ',', 'but', 'I', 'had', \"n't\", 'really', 'noticed', 'the', 'songs.<br', '/><br', '/>(originally', 'written', '10/7/2000', ')'], 'label': 'pos'}\n"
          ]
        }
      ],
      "source": [
        "print(vars(train_data.examples[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahLiDGbmx0wj"
      },
      "source": [
        "## Pre-trained Embeddings\n",
        "\n",
        "Embedding is the vector representation of each word in the vocabulary that we will use to feed the recurrent network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTpXXYkFyFTK",
        "outputId": "04be311e-c481-4be7-f5de-b6ad4c7beef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.34MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:13<00:00, 29470.07it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10002, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "MAX_VOCAB_SIZE = 10000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", # pre-trained embeddings\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "len(TEXT.vocab), len(LABEL.vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlzfISyfzHJa"
      },
      "source": [
        "We define the dataloaders with the torchtext.data.BucketIterator class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tBCWjNcyaH7"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "dataloader = {\n",
        "    'train': torchtext.legacy.data.BucketIterator(train_data, batch_size=64, shuffle=True, sort_within_batch=True, device=device),\n",
        "    'test': torchtext.legacy.data.BucketIterator(test_data, batch_size=64, device=device)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzFcDsrhzRdr"
      },
      "source": [
        "## Model\n",
        "\n",
        "This model is mainly made up of the embedding layer, which in this case we will replace with the previously downloaded vectors, and the recurrent and linear layers, which we will train from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sN09BxyzYJZ"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=2, num_layers=2, dropout=0.2, bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = torch.nn.GRU(\n",
        "            input_size=embedding_dim, \n",
        "            hidden_size=hidden_dim, \n",
        "            num_layers=num_layers, \n",
        "            dropout=dropout if num_layers > 1 else 0,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        self.fc = torch.nn.Linear(2*hidden_dim if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        # no entrenamos los embeddings\n",
        "        with torch.no_grad():\n",
        "            #text = [sent len, batch size]        \n",
        "            embedded = self.embedding(text)        \n",
        "        #embedded = [sent len, batch size, emb dim]        \n",
        "        output, hidden = self.rnn(embedded)        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        y = self.fc(output[-1,:,:].squeeze(0))\n",
        "        \"\"\" Now the batch dimension is NOT the first, this is the default behavior of recursive \n",
        "            layers in Pytorch. You can modify this by adding the option batch_first=True in the \n",
        "            recursive layer (and make sure your dataloader uses the first dimension for the batch \n",
        "            as well. \"\"\"       \n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVpJtIBd0faU"
      },
      "source": [
        "We replace the tensors in the \"embedding\" layer with the pre-trained vectors downloaded earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP964tLd0rjk",
        "outputId": "efc16ec9-3b8d-47ad-ebbe-1a31f18ad6e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model = RNN(input_dim=len(TEXT.vocab), bidirectional=True, embedding_dim=100)\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "# we zero out the weights corresponding to the tokens and <pad>\n",
        "model.embedding.weight.data[TEXT.vocab.stoi[TEXT.unk_token]] = torch.zeros(100)\n",
        "model.embedding.weight.data[TEXT.vocab.stoi[TEXT.pad_token]] = torch.zeros(100)\n",
        "\n",
        "outputs = model(torch.randint(0, len(TEXT.vocab), (100, 64)))\n",
        "outputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBzOv4ny1HSF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9psPZVmG1Ke7"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def fit(model, dataloader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gocYv6g1Pds",
        "outputId": "37703241-da2f-4fe8-b116-60788ce4626e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.61457 acc 0.65098: 100%|██████████| 391/391 [00:23<00:00, 16.84it/s]\n",
            "val_loss 0.88599 val_acc 0.50388: 100%|██████████| 391/391 [00:27<00:00, 14.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 loss 0.61457 val_loss 0.88599 acc 0.65098 val_acc 0.50388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.41138 acc 0.81278: 100%|██████████| 391/391 [00:23<00:00, 16.56it/s]\n",
            "val_loss 0.53038 val_acc 0.77739: 100%|██████████| 391/391 [00:27<00:00, 14.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 loss 0.41138 val_loss 0.53038 acc 0.81278 val_acc 0.77739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.33329 acc 0.85904: 100%|██████████| 391/391 [00:23<00:00, 16.93it/s]\n",
            "val_loss 0.36333 val_acc 0.83838: 100%|██████████| 391/391 [00:26<00:00, 14.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 loss 0.33329 val_loss 0.36333 acc 0.85904 val_acc 0.83838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.28268 acc 0.88349: 100%|██████████| 391/391 [00:23<00:00, 16.88it/s]\n",
            "val_loss 0.30692 val_acc 0.86973: 100%|██████████| 391/391 [00:27<00:00, 14.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 loss 0.28268 val_loss 0.30692 acc 0.88349 val_acc 0.86973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.24724 acc 0.89946: 100%|██████████| 391/391 [00:23<00:00, 16.82it/s]\n",
            "val_loss 0.31385 val_acc 0.86767: 100%|██████████| 391/391 [00:27<00:00, 14.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 loss 0.24724 val_loss 0.31385 acc 0.89946 val_acc 0.86767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "fit(model, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLlXbIW41Sk7"
      },
      "source": [
        "## Generating predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLsNLp_t1Vzi"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def predict(model, X):\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(X).to(device)\n",
        "        pred = model(X)\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mVvOblw1ajl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33404535-54f3-4eba-eb42-b1460309ea0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\", \"a waste of time\"]\n",
        "tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n",
        "indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n",
        "tensor = torch.tensor(indexed).permute(1,0)\n",
        "predictions = torch.argmax(predict(model, tensor), axis=1)\n",
        "predictions"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyPKIQ1/ObPd/mpHvo+8ieL5"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}